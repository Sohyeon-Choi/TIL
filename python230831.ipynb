{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 텍스트 마이닝 기본문법\n"
      ],
      "metadata": {
        "id": "mVNZU934HKH_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 문장 토큰화\n",
        "- 파이썬 머신러닝 완벽 가이드 (p.492)"
      ],
      "metadata": {
        "id": "QIRY8JemHQd_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9v9bdwH-G3OZ",
        "outputId": "d24b4b30-a34c-42cc-ec94-82299eb75ff9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "from nltk import sent_tokenize\n",
        "import nltk\n",
        "\n",
        "nltk.download('punkt') # 마침표, 개행 문자 관련 데이터 세트를 다운로드 한다."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Document = 문서\n",
        "text_sample = 'The Matrix is everywhere its all around us, here even in this room. \\\n",
        "               You can see it out your window or on your television. \\\n",
        "               You feel it when you go to work, or go to church or pay your taxes.'\n",
        "\n",
        "sentences = sent_tokenize(text=text_sample)\n",
        "print(type(sentences))\n",
        "print(len(sentences))\n",
        "print(sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OC7AKozPHoeD",
        "outputId": "cf961e27-6a51-4173-9e31-05c2533cf9bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'>\n",
            "3\n",
            "['The Matrix is everywhere its all around us, here even in this room.', 'You can see it out your window or on your television.', 'You feel it when you go to work, or go to church or pay your taxes.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 단어 토큰화\n",
        "- 문장을 각각의 단어로 다시 토큰화함"
      ],
      "metadata": {
        "id": "iRsdekUDILpU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import word_tokenize\n",
        "\n",
        "sentence = \"The Matrix is everywhere its all around us, here even in this room.\"\n",
        "words = word_tokenize(sentence)\n",
        "print(type(words))\n",
        "print(len(words))\n",
        "print(words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_JXMHNHIdL6",
        "outputId": "f537faa2-ea72-46a7-a865-d2854761899a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'>\n",
            "15\n",
            "['The', 'Matrix', 'is', 'everywhere', 'its', 'all', 'around', 'us', ',', 'here', 'even', 'in', 'this', 'room', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 문서를 단어로 토큰화 함수\n",
        "- 문서 => 문장 => 단어 ====> 단어 뭉치(?) 묶자"
      ],
      "metadata": {
        "id": "yhNBdTBYIvse"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import word_tokenize, sent_tokenize\n",
        "\n",
        "# 여러개의 문장으로 된 입력 데이터를 문장별로 단어 토큰화하는 함수\n",
        "def tokenize_text(text):\n",
        "\n",
        "  # 문장별로 분리 토큰\n",
        "  sentences = sent_tokenize(text) # 3개의 리스트\n",
        "\n",
        "  # 각 문장을 단어별로 토큰화\n",
        "  word_tokens = [word_tokenize(sentence) for sentence in sentences]\n",
        "  return word_tokens\n",
        "\n",
        "# 문서를 단어별로 토큰화 수행\n",
        "word_tokens = tokenize_text(text_sample)\n",
        "print(type(word_tokens),len(word_tokens))\n",
        "print(word_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qVLy_fSJFfF",
        "outputId": "463816c9-f731-4062-de53-8d38e41d18ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'> 3\n",
            "[['The', 'Matrix', 'is', 'everywhere', 'its', 'all', 'around', 'us', ',', 'here', 'even', 'in', 'this', 'room', '.'], ['You', 'can', 'see', 'it', 'out', 'your', 'window', 'or', 'on', 'your', 'television', '.'], ['You', 'feel', 'it', 'when', 'you', 'go', 'to', 'work', ',', 'or', 'go', 'to', 'church', 'or', 'pay', 'your', 'taxes', '.']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_sample = \"I have withdrawn from the musical Tiananmen, Piser said in a brief signed statement on Instagram. Piser was on tour performing hit Broadway songs in the Chinese metropolis of Shanghai when he made the announcement, according to his Instagram posts and Chinese state media reports. In China, the Tiananmen Square pro-democracy protests, which swept Beijing and dozens of other Chinese cities in 1989 – and ended in a bloody military crackdown that cost the lives of hundreds, if not thousands, of protesters – remain a major political taboo.\"\n",
        "word_tokens = tokenize_text(text_sample)\n",
        "print(type(word_tokens),len(word_tokens))\n",
        "print(word_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TTi9BO_1JxxQ",
        "outputId": "ed4f88d5-309f-487f-ff30-859b4dc0ebe1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'> 3\n",
            "[['I', 'have', 'withdrawn', 'from', 'the', 'musical', 'Tiananmen', ',', 'Piser', 'said', 'in', 'a', 'brief', 'signed', 'statement', 'on', 'Instagram', '.'], ['Piser', 'was', 'on', 'tour', 'performing', 'hit', 'Broadway', 'songs', 'in', 'the', 'Chinese', 'metropolis', 'of', 'Shanghai', 'when', 'he', 'made', 'the', 'announcement', ',', 'according', 'to', 'his', 'Instagram', 'posts', 'and', 'Chinese', 'state', 'media', 'reports', '.'], ['In', 'China', ',', 'the', 'Tiananmen', 'Square', 'pro-democracy', 'protests', ',', 'which', 'swept', 'Beijing', 'and', 'dozens', 'of', 'other', 'Chinese', 'cities', 'in', '1989', '–', 'and', 'ended', 'in', 'a', 'bloody', 'military', 'crackdown', 'that', 'cost', 'the', 'lives', 'of', 'hundreds', ',', 'if', 'not', 'thousands', ',', 'of', 'protesters', '–', 'remain', 'a', 'major', 'political', 'taboo', '.']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_sample = \"팝페라 테너 임형주가 다음 달 3일(이하 현지시간) 몽골 울란바토르에서 열리는 프란치스코 교황 집전 미사의 식전행사에서 엔딩 무대를 장식합니다. 오늘(31일) 가요계와 가톨릭계에 따르면 임형주는 9월 3일 오후 4시 몽골 울란바토르 스텝 아레나 경기장에서 열리는 교황 집전 미사의 식전행사에서 엔딩 무대에 올라 '아베 마리아'(Ave Maria)와 '유 레이즈 미 업'(You Raise Me Up), '생명의 양식'(Panis Angelicus) 등 세 곡을 들려줍니다. 그에 앞서 몽골 전통공연단과 베트남 전통무용단이 공연합니다. 임형주는 이 행사에서 한국을 대표하는 음악가로 초청된 것으로 전해졌습니다. 몽골 천주교회 측이 그를 공식 초청하는 방안을 교황청에 전달했고, 교황청이 이를 승인한 것으로 알려졌습니다. 프란치스코 교황은 31일부터 다음 달 4일까지 4박 5일 일정으로 몽골을 방문합니다.\"\n",
        "word_tokens = tokenize_text(text_sample)\n",
        "print(type(word_tokens),len(word_tokens))\n",
        "print(word_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-5Z131fqKTVy",
        "outputId": "a591616d-8874-4435-b809-3826f7cdc8b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'> 6\n",
            "[['팝페라', '테너', '임형주가', '다음', '달', '3일', '(', '이하', '현지시간', ')', '몽골', '울란바토르에서', '열리는', '프란치스코', '교황', '집전', '미사의', '식전행사에서', '엔딩', '무대를', '장식합니다', '.'], ['오늘', '(', '31일', ')', '가요계와', '가톨릭계에', '따르면', '임형주는', '9월', '3일', '오후', '4시', '몽골', '울란바토르', '스텝', '아레나', '경기장에서', '열리는', '교황', '집전', '미사의', '식전행사에서', '엔딩', '무대에', '올라', \"'아베\", '마리아', \"'\", '(', 'Ave', 'Maria', ')', '와', \"'\", '유', '레이즈', '미', '업', \"'\", '(', 'You', 'Raise', 'Me', 'Up', ')', ',', \"'생명의\", '양식', \"'\", '(', 'Panis', 'Angelicus', ')', '등', '세', '곡을', '들려줍니다', '.'], ['그에', '앞서', '몽골', '전통공연단과', '베트남', '전통무용단이', '공연합니다', '.'], ['임형주는', '이', '행사에서', '한국을', '대표하는', '음악가로', '초청된', '것으로', '전해졌습니다', '.'], ['몽골', '천주교회', '측이', '그를', '공식', '초청하는', '방안을', '교황청에', '전달했고', ',', '교황청이', '이를', '승인한', '것으로', '알려졌습니다', '.'], ['프란치스코', '교황은', '31일부터', '다음', '달', '4일까지', '4박', '5일', '일정으로', '몽골을', '방문합니다', '.']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stopwords 제거\n",
        "- 불용어 : 분석에 큰 의미가 없는 단어\n",
        "- p.495"
      ],
      "metadata": {
        "id": "KCILhYm4Km0g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bzh2YrVQKufa",
        "outputId": "61eec37b-9b14-412b-f3d7-f5ad071db6c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"영어 불용어 갯수:\", len(nltk.corpus.stopwords.words('english')))\n",
        "print(nltk.corpus.stopwords.words('english')[:20])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Tx3V5OFK-uc",
        "outputId": "efc7deaf-d168-4270-81cc-59c7d05390df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "영어 불용어 갯수: 179\n",
            "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 불용어 제거"
      ],
      "metadata": {
        "id": "IbDgeU24Li7c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_sample = 'The Matrix is everywhere its all around us, here even in this room. \\\n",
        "               You can see it out your window or on your television. \\\n",
        "               You feel it when you go to work, or go to church or pay your taxes.'\n",
        "word_tokens = tokenize_text(text_sample)\n",
        "\n",
        "# 특정 도메인에서 분석을 하려고 함\n",
        "stopwords = nltk.corpus.stopwords.words('english')\n",
        "stopwords = stopwords + ['everywhere', 'us']\n",
        "\n",
        "all_tokens = []\n",
        "# 위 예제의 3개의 문장별로 얻은 word_tokens list 에 대해 stop word 제거 Loop\n",
        "for sentence in word_tokens:\n",
        "    filtered_words=[]\n",
        "    # 개별 문장별로 tokenize된 sentence list에 대해 stop word 제거 Loop\n",
        "    for word in sentence:\n",
        "        #소문자로 모두 변환합니다.\n",
        "        word = word.lower()\n",
        "        # tokenize 된 개별 word가 stop words 들의 단어에 포함되지 않으면 word_tokens에 추가\n",
        "        if word not in stopwords:\n",
        "            filtered_words.append(word)\n",
        "    all_tokens.append(filtered_words)\n",
        "\n",
        "print(all_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zSwe3oONLj-p",
        "outputId": "63d4b8a6-546c-4e6b-bc27-bb5053420985"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['matrix', 'around', ',', 'even', 'room', '.'], ['see', 'window', 'television', '.'], ['feel', 'go', 'work', ',', 'go', 'church', 'pay', 'taxes', '.']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 어근 추출"
      ],
      "metadata": {
        "id": "Wz4X5pqmOGL_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import LancasterStemmer\n",
        "stemmer = LancasterStemmer()\n",
        "\n",
        "print(stemmer.stem('working'),stemmer.stem('works'),stemmer.stem('worked'))\n",
        "print(stemmer.stem('amusing'),stemmer.stem('amuses'),stemmer.stem('amused'))\n",
        "print(stemmer.stem('happier'),stemmer.stem('happiest'))\n",
        "print(stemmer.stem('fancier'),stemmer.stem('fanciest'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-EjXbgiOIhY",
        "outputId": "84b773de-f332-4f60-a269-81e3b2b3c77f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "work work work\n",
            "amus amus amus\n",
            "happy happiest\n",
            "fant fanciest\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "\n",
        "lemma = WordNetLemmatizer()\n",
        "print(lemma.lemmatize('amusing','v'),lemma.lemmatize('amuses','v'),lemma.lemmatize('amused','v'))\n",
        "print(lemma.lemmatize('happier','a'),lemma.lemmatize('happiest','a'))\n",
        "print(lemma.lemmatize('fancier','a'),lemma.lemmatize('fanciest','a'))"
      ],
      "metadata": {
        "id": "dkJm4aEyOR6C",
        "outputId": "961ae8e3-b843-4d78-fbd0-b0719ddcc506",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "amuse amuse amuse\n",
            "happy happy\n",
            "fancy fancy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터 불러오기"
      ],
      "metadata": {
        "id": "ycsHjiY6VPNn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5t3pI_hIVTPQ",
        "outputId": "ad29e045-a13a-4666-eea9-34464c27fb0f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "DATA_PATH = '/content/drive/MyDrive/Colab Notebooks/2023/멀티캠퍼스/data/text_mining/'\n",
        "\n",
        "# p.520\n",
        "review_df = pd.read_csv(DATA_PATH + './labeledTrainData.tsv', header=0, sep=\"\\t\", quoting=3)\n",
        "review_df.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "sl5cgBFqVt9I",
        "outputId": "0b5d13f0-b774-4bc7-a28f-82c081512bf0"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         id  sentiment                                             review\n",
              "0  \"5814_8\"          1  \"With all this stuff going down at the moment ...\n",
              "1  \"2381_9\"          1  \"\\\"The Classic War of the Worlds\\\" by Timothy ...\n",
              "2  \"7759_3\"          0  \"The film starts with a manager (Nicholas Bell..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6d8a78f6-42ac-4605-b07e-88818d3470f9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\"5814_8\"</td>\n",
              "      <td>1</td>\n",
              "      <td>\"With all this stuff going down at the moment ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\"2381_9\"</td>\n",
              "      <td>1</td>\n",
              "      <td>\"\\\"The Classic War of the Worlds\\\" by Timothy ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\"7759_3\"</td>\n",
              "      <td>0</td>\n",
              "      <td>\"The film starts with a manager (Nicholas Bell...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6d8a78f6-42ac-4605-b07e-88818d3470f9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6d8a78f6-42ac-4605-b07e-88818d3470f9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6d8a78f6-42ac-4605-b07e-88818d3470f9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "review_df['review'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "id": "2OyK7kcPW5mv",
        "outputId": "e787b059-0db5-492e-ad9a-66635b1d7cf9"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\"With all this stuff going down at the moment with MJ i\\'ve started listening to his music, watching the odd documentary here and there, watched The Wiz and watched Moonwalker again. Maybe i just want to get a certain insight into this guy who i thought was really cool in the eighties just to maybe make up my mind whether he is guilty or innocent. Moonwalker is part biography, part feature film which i remember going to see at the cinema when it was originally released. Some of it has subtle messages about MJ\\'s feeling towards the press and also the obvious message of drugs are bad m\\'kay.<br /><br />Visually impressive but of course this is all about Michael Jackson so unless you remotely like MJ in anyway then you are going to hate this and find it boring. Some may call MJ an egotist for consenting to the making of this movie BUT MJ and most of his fans would say that he made it for the fans which if true is really nice of him.<br /><br />The actual feature film bit when it finally starts is only on for 20 minutes or so excluding the Smooth Criminal sequence and Joe Pesci is convincing as a psychopathic all powerful drug lord. Why he wants MJ dead so bad is beyond me. Because MJ overheard his plans? Nah, Joe Pesci\\'s character ranted that he wanted people to know it is he who is supplying drugs etc so i dunno, maybe he just hates MJ\\'s music.<br /><br />Lots of cool things in this like MJ turning into a car and a robot and the whole Speed Demon sequence. Also, the director must have had the patience of a saint when it came to filming the kiddy Bad sequence as usually directors hate working with one kid let alone a whole bunch of them performing a complex dance scene.<br /><br />Bottom line, this movie is for people who like MJ on one level or another (which i think is most people). If not, then stay away. It does try and give off a wholesome message and ironically MJ\\'s bestest buddy in this movie is a girl! Michael Jackson is truly one of the most talented people ever to grace this planet but is he guilty? Well, with all the attention i\\'ve gave this subject....hmmm well i don\\'t know because people can be different behind closed doors, i know this for a fact. He is either an extremely nice but stupid guy or one of the most sickest liars. I hope he is not the latter.\"'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 텍스트 전처리"
      ],
      "metadata": {
        "id": "-Lywm8w1W-xp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "review_df['review'] = review_df['review'].str.replace('<br />', ' ')\n",
        "review_df['review'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "id": "Q-Mi0LoqXAZN",
        "outputId": "6d14e6e0-0845-4e4e-b3be-5bb557656968"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\"With all this stuff going down at the moment with MJ i\\'ve started listening to his music, watching the odd documentary here and there, watched The Wiz and watched Moonwalker again. Maybe i just want to get a certain insight into this guy who i thought was really cool in the eighties just to maybe make up my mind whether he is guilty or innocent. Moonwalker is part biography, part feature film which i remember going to see at the cinema when it was originally released. Some of it has subtle messages about MJ\\'s feeling towards the press and also the obvious message of drugs are bad m\\'kay.  Visually impressive but of course this is all about Michael Jackson so unless you remotely like MJ in anyway then you are going to hate this and find it boring. Some may call MJ an egotist for consenting to the making of this movie BUT MJ and most of his fans would say that he made it for the fans which if true is really nice of him.  The actual feature film bit when it finally starts is only on for 20 minutes or so excluding the Smooth Criminal sequence and Joe Pesci is convincing as a psychopathic all powerful drug lord. Why he wants MJ dead so bad is beyond me. Because MJ overheard his plans? Nah, Joe Pesci\\'s character ranted that he wanted people to know it is he who is supplying drugs etc so i dunno, maybe he just hates MJ\\'s music.  Lots of cool things in this like MJ turning into a car and a robot and the whole Speed Demon sequence. Also, the director must have had the patience of a saint when it came to filming the kiddy Bad sequence as usually directors hate working with one kid let alone a whole bunch of them performing a complex dance scene.  Bottom line, this movie is for people who like MJ on one level or another (which i think is most people). If not, then stay away. It does try and give off a wholesome message and ironically MJ\\'s bestest buddy in this movie is a girl! Michael Jackson is truly one of the most talented people ever to grace this planet but is he guilty? Well, with all the attention i\\'ve gave this subject....hmmm well i don\\'t know because people can be different behind closed doors, i know this for a fact. He is either an extremely nice but stupid guy or one of the most sickest liars. I hope he is not the latter.\"'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 영어 문자열이 아닌 모든 문자는 공백으로 변환\n",
        "review_df['review'] = review_df['review'].apply(lambda x: re.sub(\"[^a-zA-Z]\", \" \", x))\n",
        "review_df['review'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "id": "3T2B-6I3XKUU",
        "outputId": "2c6e6f43-1f1f-49de-8ce8-fd4d300ea66c"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' With all this stuff going down at the moment with MJ i ve started listening to his music  watching the odd documentary here and there  watched The Wiz and watched Moonwalker again  Maybe i just want to get a certain insight into this guy who i thought was really cool in the eighties just to maybe make up my mind whether he is guilty or innocent  Moonwalker is part biography  part feature film which i remember going to see at the cinema when it was originally released  Some of it has subtle messages about MJ s feeling towards the press and also the obvious message of drugs are bad m kay   Visually impressive but of course this is all about Michael Jackson so unless you remotely like MJ in anyway then you are going to hate this and find it boring  Some may call MJ an egotist for consenting to the making of this movie BUT MJ and most of his fans would say that he made it for the fans which if true is really nice of him   The actual feature film bit when it finally starts is only on for    minutes or so excluding the Smooth Criminal sequence and Joe Pesci is convincing as a psychopathic all powerful drug lord  Why he wants MJ dead so bad is beyond me  Because MJ overheard his plans  Nah  Joe Pesci s character ranted that he wanted people to know it is he who is supplying drugs etc so i dunno  maybe he just hates MJ s music   Lots of cool things in this like MJ turning into a car and a robot and the whole Speed Demon sequence  Also  the director must have had the patience of a saint when it came to filming the kiddy Bad sequence as usually directors hate working with one kid let alone a whole bunch of them performing a complex dance scene   Bottom line  this movie is for people who like MJ on one level or another  which i think is most people   If not  then stay away  It does try and give off a wholesome message and ironically MJ s bestest buddy in this movie is a girl  Michael Jackson is truly one of the most talented people ever to grace this planet but is he guilty  Well  with all the attention i ve gave this subject    hmmm well i don t know because people can be different behind closed doors  i know this for a fact  He is either an extremely nice but stupid guy or one of the most sickest liars  I hope he is not the latter  '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 훈련데이터, 테스트 데이터 분리"
      ],
      "metadata": {
        "id": "mYM0ooypYsFf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "class_df = review_df['sentiment'] # Y : 1은 긍정, 0은 부정\n",
        "feature_df = review_df.drop(['id', 'sentiment'], axis = 1) # review만 남음\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    feature_df, class_df, test_size = 0.3, random_state=156\n",
        ")\n",
        "\n",
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YOWO4Vz2Xtaw",
        "outputId": "8bcd41f1-e244-4661-ad9e-9f6186bbc29b"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((17500, 1), (7500, 1), (17500,), (7500,))"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 학습"
      ],
      "metadata": {
        "id": "Y7XWi2DiZus5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('cnt_vect', CountVectorizer(stop_words='english', ngram_range=(1, 2))),\n",
        "    ('lr_clf', LogisticRegression(solver='liblinear', C=10))\n",
        "])\n",
        "\n",
        "pipeline.fit(X_train['review'], y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "id": "09EZrYzxZ1LI",
        "outputId": "78e421fe-a8cb-4ea2-df5b-fa07c8bd6ca7"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('cnt_vect',\n",
              "                 CountVectorizer(ngram_range=(1, 2), stop_words='english')),\n",
              "                ('lr_clf', LogisticRegression(C=10, solver='liblinear'))])"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;cnt_vect&#x27;,\n",
              "                 CountVectorizer(ngram_range=(1, 2), stop_words=&#x27;english&#x27;)),\n",
              "                (&#x27;lr_clf&#x27;, LogisticRegression(C=10, solver=&#x27;liblinear&#x27;))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;cnt_vect&#x27;,\n",
              "                 CountVectorizer(ngram_range=(1, 2), stop_words=&#x27;english&#x27;)),\n",
              "                (&#x27;lr_clf&#x27;, LogisticRegression(C=10, solver=&#x27;liblinear&#x27;))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer(ngram_range=(1, 2), stop_words=&#x27;english&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=10, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred = pipeline.predict(X_test['review'])\n",
        "pred_probs = pipeline.predict_proba(X_test['review'])[:, 1]\n",
        "\n",
        "print('예측 정확도는 {0:.4f}, ROC-AUC는 {1:.4f}'.format(accuracy_score(y_test ,pred),\n",
        "                                         roc_auc_score(y_test, pred_probs)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MTf4ttEHaze3",
        "outputId": "b8d9f292-a628-4080-e753-42737524d28a"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "예측 정확도는 0.8861, ROC-AUC는 0.9503\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- TF IDF 활용해서 측정"
      ],
      "metadata": {
        "id": "COh1EO-7Whrq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%timeit\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('cnt_vect', TfidfVectorizer(stop_words='english', ngram_range=(1, 2))),\n",
        "    ('lr_clf', LogisticRegression(solver='liblinear', C=10))\n",
        "])\n",
        "\n",
        "pipeline.fit(X_train['review'], y_train)\n",
        "pred = pipeline.predict(X_test['review'])\n",
        "pred_probs = pipeline.predict_proba(X_test['review'])[:, 1]\n",
        "\n",
        "print('예측 정확도는 {0:.4f}, ROC-AUC는 {1:.4f}'.format(accuracy_score(y_test ,pred),\n",
        "                                         roc_auc_score(y_test, pred_probs)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AsqtHRFablDm",
        "outputId": "1d2a61b0-5db2-4b39-9c5f-11e9c7fec507"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "예측 정확도는 0.8936, ROC-AUC는 0.9598\n",
            "예측 정확도는 0.8936, ROC-AUC는 0.9598\n",
            "예측 정확도는 0.8936, ROC-AUC는 0.9598\n",
            "예측 정확도는 0.8936, ROC-AUC는 0.9598\n",
            "예측 정확도는 0.8936, ROC-AUC는 0.9598\n",
            "예측 정확도는 0.8936, ROC-AUC는 0.9598\n",
            "예측 정확도는 0.8936, ROC-AUC는 0.9598\n",
            "예측 정확도는 0.8936, ROC-AUC는 0.9598\n",
            "24.3 s ± 1.54 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = TfidfVectorizer()\n",
        "X = vectorizer.fit_transform(review_df['review'])\n",
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-aSv0mvcsoY",
        "outputId": "43d72d64-4a75-4403-ab3d-30f5b792df03"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 73246)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit_transform(review_df['review'])\n",
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gOe89nLNc5Ld",
        "outputId": "516638ab-ed0c-430f-e125-b07ca64423e8"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 73246)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KDxHizyGdRm2",
        "outputId": "eccf1c3d-3986-4a54-807e-5482ef138933"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (0, 71786)\t4\n",
            "  (0, 1558)\t4\n",
            "  (0, 65032)\t11\n",
            "  (0, 62272)\t1\n",
            "  (0, 26679)\t3\n",
            "  (0, 18635)\t1\n",
            "  (0, 3639)\t2\n",
            "  (0, 64811)\t19\n",
            "  (0, 42129)\t1\n",
            "  (0, 41901)\t11\n",
            "  (0, 69374)\t2\n",
            "  (0, 61392)\t1\n",
            "  (0, 37621)\t1\n",
            "  (0, 65592)\t9\n",
            "  (0, 29773)\t3\n",
            "  (0, 43124)\t2\n",
            "  (0, 70705)\t1\n",
            "  (0, 45213)\t1\n",
            "  (0, 18164)\t1\n",
            "  (0, 29351)\t1\n",
            "  (0, 2147)\t10\n",
            "  (0, 64904)\t1\n",
            "  (0, 70699)\t2\n",
            "  (0, 71838)\t1\n",
            "  (0, 42364)\t2\n",
            "  :\t:\n",
            "  (0, 66844)\t1\n",
            "  (0, 63836)\t1\n",
            "  (0, 21498)\t1\n",
            "  (0, 27026)\t1\n",
            "  (0, 48796)\t1\n",
            "  (0, 71002)\t2\n",
            "  (0, 3772)\t1\n",
            "  (0, 25678)\t1\n",
            "  (0, 62417)\t1\n",
            "  (0, 29861)\t1\n",
            "  (0, 18346)\t1\n",
            "  (0, 9203)\t1\n",
            "  (0, 5208)\t1\n",
            "  (0, 17121)\t1\n",
            "  (0, 5517)\t1\n",
            "  (0, 11758)\t1\n",
            "  (0, 18459)\t1\n",
            "  (0, 22262)\t1\n",
            "  (0, 19924)\t1\n",
            "  (0, 22137)\t1\n",
            "  (0, 62320)\t1\n",
            "  (0, 58569)\t1\n",
            "  (0, 37217)\t1\n",
            "  (0, 30273)\t1\n",
            "  (0, 36529)\t1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## p.566\n",
        "- 캐글 Mercari Price Suggesstion Challenge\n",
        "- 기존 정형데이터 + 텍스트 마이닝 ==> 지도학습"
      ],
      "metadata": {
        "id": "oIn2GYFddjo8"
      }
    }
  ]
}